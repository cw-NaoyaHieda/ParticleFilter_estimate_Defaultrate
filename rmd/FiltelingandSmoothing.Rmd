---
title: "Filteling and Smoothing"
author: "稗田尚弥"
date: "`r Sys.Date()`"
output: html_document
---

去年やっていたことの復讐  
POMPに逃げる前に、どこまで行っていたのか  
どこでつまずいたのか確認  
確認していたら、粒子フィルタリングじゃなくてモンテカルロフィルタになっていること判明。

提案分布をシュミレーションしているARモデルと同じ分布としている．

```{r setup, include=FALSE,message=F,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
```

## パッケージの読み込み
ところどころ、開始からの時間を出力しておく
```{r package}
library(rgl)
library(mvtnorm)
library(reshape2)
library(doSNOW)
library(ggplot2)
library(pforeach)
rm(list=ls())
start_time <- Sys.time()
```

とりあえず、ARモデルにに従って、$PDと\rho$を生成して、$DR$をHullの密度関数に従って、棄却法で発生

## シミュレーション
```{r}
source("../script/データ編集.R", encoding = "UTF-8")
source('../script/DR_density.R', encoding = 'UTF-8')
source('../script/AR_sim.R', encoding = 'UTF-8')
set.seed(708)
answer<-AR_sim(time=10000,rho = 0.06,PD=0.035)
head(answer)
data_for_Kalman<-data.frame(dt=c(1:length(answer$DR)),DR=answer$DR)
colnames(data_for_Kalman)<-c("dt","Default_Rate")
str(data_for_Kalman)
Sys.time()-start_time
```

## 初期設定  
最適化を行う際に、変数に[0,1]の制約があると不便なので、シグモイド関数の逆関数で変換したものを利用する。今後、これをで$\theta=\{\theta_{PD},\theta_{rho}\}$表す。シグモイド関数と逆関数を準備。
```{r}
sig<-function(x){(tanh(x)+1)/2}
sig_env<-function(y){(1/2)*log(y/(1-y))}
```

Particlefilterを行う上で必要な初期値を、正規分布からサンプリング  
サンプリングの平均値は、$PD,\rho$のシミュレーションの初期値を、シグモイド逆関数にかけたもの  
分散はどちらも0.01、共分散は0でサンプリングする
```{r}
first_theta_m<-c(sig_env(0.06),sig_env(0.035))
first_theta_v<-matrix(c(0.01,0,0,0.01),ncol=2)
```

フィルタリングの際に発生したParticleを記録しておく、変数の準備  
フィルタリング用いる分布(提案分布だとか重点分布という名前)の分布は、  
シミュレーションしたARモデルと同じ  
・・・去年、それでも構わないと思っていたけど、これだと粒子フィルタリングじゃなくてモンテカルロフィルタリングになっている。
```{r}
theta<-c()
state<-c()
theta_mu<-c(sig_env(0.06),sig_env(0.035))
theta_tau<-c(0.99,0.99)
theta_sigma<-matrix(c(0.0005,0,0,0.0004),ncol=2)
```

## フィルタリング
パーティクルの数は、128個  
先ほど設定した初期値で、$\theta$の初期値を発生。状態変数への変換も行う。
```{r}
N <- 1000
proposal_theta_m <- theta_mu
proposal_theta_v <- theta_sigma
theta_0<-rmvnorm(N , mean=theta_mu , sigma = theta_sigma)
state_0<-sig(theta_0)
```

PDやrhoの初期値の中に、0や1のものがあると、DRの密度が計算できないので、そこだけ変換
```{r}
state_0[,1][state_0[,1]==0] <- 1e-60
state_0[,2][state_0[,2]==0] <- 1e-60
state_0[,1][state_0[,1]==1] <- 0.9999999
state_0[,2][state_0[,2]==1] <- 0.9999999
weight_0<-rep(1/N,N)
```

時点1でのフィルタリング開始  
ARモデルに従ってt=1での状態変数のParticle発生  
```{r}
theta<-t(apply(theta_0,1,function(x) rmvnorm(1,mean=theta_mu+theta_tau*(x-theta_mu),sigma = theta_sigma)))
state<-sig(theta)
#PDやrhoは0と1を取れないので、そこだけ変換
state[,1][state[,1]==0] <- 1e-60
state[,2][state[,2]==0] <- 1e-60
state[,1][state[,1]==1] <- 0.9999999
state[,2][state[,2]==1] <- 0.9999999
```
重みを計算  
提案分布=実際の分布で、モンテカルロフィルタになっているので、重みを計算する際の分母分子が消える
```{r}
weight<-apply(state,1,function(x) g_DR.fn(rho=x[1],PD=x[2],data_for_Kalman[1,2]))
weight<-weight/sum(weight)
state<-cbind(state,weight=weight)
```
累積相対尤度(重み)の計算  
状態変数と、重み、累積相対尤度がくっついたデータフレームが出来ていることを確認
```{r}
state<-cbind(state,ruiseki=cumsum(state[,3])/sum(state[,3]))
head(state,n=10)
tail(state,n=10)
```
リサンプリング関数の設定  
一様分布(0,1)から発生した乱数と累積相対尤度を用いてサンプリング
```{r}
A_r<-function(r,state){
  return(which(r>=state[,4])[1])
}
```
リサンプリングする必要があるかどうか判定した上で、リサンプリング  
リサンプリングしたかどうかのチェック変数も用意。リサンプリングしたら1、しなかったら0。
```{r}
re_state_num<-c()
if(sum(weight^2)^-1 < N/10){
  re_state_num <- apply(data.frame(i = 1:N, x = runif(N)),1,
                        function(x) A_r((x[1]-1+x[2])/N),state)
  re_state <- state[re_state_num,c(1,2,3)]
  re_theta <- theta[re_state_num,]
  re_state[,3] <- rep(1/N,N)
  resample_check <- 1
} else{
  re_state_num<-seq(1:N)
  re_state<-state[,c(1,2,3)]
  re_theta<-theta
  resample_check <- 0
}
```
結果の保存  
state_100にリサンプリングする前の状態変数と、重みと、リサンプリングした状態変数のデータのリスト
```{r}
state_100<-list(data.frame(rho=state[,1],
                           PD=state[,2],weight=weight,
                           re_rho=re_state[,1],
                           re_PD=re_state[,2],
                           re_weight=re_state[,3]))
head(state_100[[1]],n=10)
Sys.time()-start_time
```
繰り返し処理の準備。並列処理で複数のコアをつかう準備。  
簡単に言うと、各コアに並列処理で使う関数や変数を渡しておく  
複数のコアを活用しているのは、Partilceの発生と、weightの計算と、リサンプリング
```{r}
theta_100<-list(data.frame(re_theta))
cl <- makeCluster(rep('localhost', 7))
clusterExport(cl, c("dmvnorm","rmvnorm","A_r","N","g_DR.fn",
                    "theta_tau","theta_mu","theta_sigma","proposal_theta_v","runif","dt","rt"))
Sys.time()-start_time
```
こっからは繰り返し
```{r}
###2~
for(j in 2:length(data_for_Kalman[,1])){
  #前回のthetaを事前分布の平均として利用
  post_theta<-re_theta
  theta<-c()
  state<-c()
  #Particle発生
  theta<-t(parApply(cl,post_theta,1,function(x){
   rmvnorm(1,mean=theta_mu+theta_tau*(x-theta_mu),
           sigma=theta_sigma)}))
  state<-sig(theta)
  state[state[,1]<1e-60,1]<-1e-60
  state[state[,2]<1e-60,2]<-1e-60
  state[state[,1]>0.99999,1]<-0.99999
  state[state[,2]>0.99999,2]<-0.99999
  #重み計算
  weight_solution<-data.frame(post_theta,state_100[[j-1]][,6],theta,state,data_for_Kalman[j,2])
  weight<-parApply(cl,weight_solution,1,function(x){
    x[3]*g_DR.fn(rho=x[6],PD=x[7],DR=x[8])
      })
  weight<-weight/sum(weight)
  state<-cbind(state,weight=weight)
  state<-cbind(state,ruiseki=cumsum(state[,3])/sum(state[,3]))
  re_state_num<-c()
  if(sum(weight^2)^-1 < N/10){
    clusterExport(cl,"state")
    re_state_num<-parApply(cl,data.frame(i = 1:N, x = runif(N)),1,
                           function(x) A_r((x[1]-1+x[2])/N,state))
    re_state<-state[re_state_num,c(1,2,3)]
    re_theta<-theta[re_state_num,]
    re_state[,3]<-rep(1/N,N)
    resample_check <- 1
  } else{
    re_state<-state[,c(1,2,3)]
    re_theta<-theta
    resample_check <- 0
  }
    print(j)
  state_100<- c(state_100,list(data.frame(rho=state[,1],PD=state[,2],
                                          weight=weight,re_rho=re_state[,1],
                                          re_PD=re_state[,2],
                                          re_weight=re_state[,3])))
  theta_100<-c(theta_100,list(data.frame(re_theta)))
}
stopCluster(cl)
Sys.time()-start_time
```

## フィルタリング結果の図
各Particleから期待値を計算して、それを状態変数の推定値とする。
```{r}
tmp<-state_100
re_PD=c()
re_rho=c()
PD=c()
rho=c()
for(i in 1:length(tmp)){
  re_PD_tmp<-sum(tmp[[i]][,5]*tmp[[i]][,6])
  re_rho_tmp<-sum(tmp[[i]][,4]*tmp[[i]][,6])
  PD_tmp<-sum(tmp[[i]][,2]*tmp[[i]][,3])
  rho_tmp<-sum(tmp[[i]][,1]*tmp[[i]][,3])
  re_PD=c(re_PD,re_PD_tmp)
  re_rho=c(re_rho,re_rho_tmp)
  PD=c(PD,PD_tmp)
  rho=c(rho,rho_tmp)
}

```
5,25,75,95%点を計算
```{r}  
qu<-data.frame(t(sapply(state_100,function(x) representative_value.fn(x[,c(4,5,6)]))))
```
$\rho$の推定結果をデータフレームにまとめてプロット
```{r}
plot_d<-data.frame(dt=c(1:length(data_for_Kalman[,1])),
                   answer=answer$rho,estimate_rho=re_rho,
                   two_fif_rho=qu$two_fif_rho,
                   twenty_fif_rho=qu$twenty_fif_rho,
                   seventy_fif_rho=qu$seventy_fif_rho,
                   nine_fif=qu$nine_fif_rho)
  
print(ggplot(plot_d,aes(x=dt))+
        geom_line(aes(y=answer,colour="answer"))+
        geom_line(aes(y=estimate_rho,colour="filter"))+
        geom_ribbon(aes(ymin=twenty_fif_rho, ymax=seventy_fif_rho,fill="50%"),alpha = 0.3)+
        geom_ribbon(aes(ymin=two_fif_rho, ymax=nine_fif,fill="90%"),alpha = 0.3)+
        theme_bw(15)+
        theme(legend.position=c(.85,.75),legend.background=element_blank())+
        ylab(expression(rho))+
        scale_color_manual(name='', values=c("answer" = "red", "filter" = "blue"))+
        scale_fill_manual(name='', values=c("50%" = "blue", "90%" = "gray")))
```
同様にしてPDもプロット
```{r}
  
plot_d<-data.frame(dt=c(1:length(data_for_Kalman[,1])),
                   answer=answer$PD,estimate_PD=re_PD,
                   two_fif_pd=qu$two_fif_pd,
                   twenty_fif_pd=qu$twenty_fif_pd,
                   seventy_fif_pd=qu$seventy_fif_pd,
                   nine_fif=qu$nine_fif_pd)
  
print(ggplot(plot_d,aes(x=dt))+geom_line(aes(y=answer,colour="answer"))+
        geom_line(aes(y=estimate_PD,colour="filter"))+
        geom_ribbon(aes(ymin=twenty_fif_pd, ymax=seventy_fif_pd,fill="50%"),alpha = 0.3)+
        geom_ribbon(aes(ymin=two_fif_pd, ymax=nine_fif,fill="90%"),alpha = 0.3)+
        theme_bw(15)+
        theme(legend.position=c(.85,.75),legend.background=element_blank())+
        ylab(expression(pd))+
        scale_color_manual(name='', values=c("answer" = "red", "filter" = "blue"))+
        scale_fill_manual(name='', values=c("50%" = "blue", "90%" = "gray")))

Sys.time()-start_time
```

## 平滑化 Forward Filtering Backward Smoothing

フィルタリングの一番最後のウェイトを与える  
リサンプリングの関数を平滑化用に修正  
フィルタリングと同じようにコアの準備
```{r,eval=FALSE}
weight_T<-list(state_100[[length(data_for_Kalman[,1])]][,6])
A_r<-function(r,weiht){
  return(which(r>=weight)[1])
}
cl <- makeCluster(rep('localhost', 7))
clusterExport(cl, c("dmvnorm","g_DR.fn","theta_tau","theta_mu","theta_sigma","proposal_theta_v"))
sm_state<-list(state_100[[length(data_for_Kalman[,1])]][,c(4,5,6)])
```
平滑化に関しては、コメント参照
```{r,eval=FALSE}
clusterExport(cl, c("theta_100","state_100","N"))
#時系列は、並列化できないので順番に処理
for(n in c(length(data_for_Kalman[,1])-1):1){
  weight_n<-c()
  #n+1とnの状態変数，ウェイトを取得
  #上記二つと平滑化のn+1番目のウェイトを取得
  a <- data.frame(theta_100[[n+1]],
                  n1_weight=state_100[[n+1]][,6],
                  theta_100[[n]],
                  n_weight=state_100[[n]][,6],
                  weight_T=weight_T[[length(data_for_Kalman[,1])-n]],
                  n=n)
  #平滑化ウェイトの分子計算
  bunsi<-parApply(cl,
                  a,
                  1,
                  function(x)
                  sum(apply(data.frame(i=1:N),1, function (y) x[7]*dmvnorm(as.numeric(x[c(1,2)]),
                  mean=theta_mu+(as.numeric(theta_100[[x[8]]][y,c(1,2)])-theta_mu)*
                  theta_tau,sigma=theta_sigma))))
  
  
  #平滑化ウェイトの分母計算
  bunbo<-parApply(cl,
                  a,
                  1,
                  function(x)
                  sum(apply(data.frame(i=1:N),1, 
                  function(y)
                  x[6]*dmvnorm(as.numeric(theta_100[[x[8]+1]][y,c(1,2)]),
                  mean=theta_mu+(x[c(4,5)]-theta_mu)*theta_tau,
                  sigma = theta_sigma))))
  
  
  weight_n<-c(state_100[[n]][,6]*bunsi/bunbo)
  
  weight_n<-weight_n/sum(weight_n)
  #必要ならば平滑化ウェイトでリサンプリング　いったんなし
  tmp<-runif(N,0,1)
  if(sum(weight_n^2)^-1 < N/10){
  sm_state_num<-apply(data.frame(tmp),1,function(x)A_r(x,cumsum(weight_n)/sum(weight_n)))
   }
  else{
     sm_state_num <- 1:N
  }
  
  sm_state<-c(sm_state,
              list(data.frame(state_100[[n]][sm_state_num,c(4,5)],
                              weight_n[sm_state_num]/sum(weight_n[sm_state_num]))))
  weight_T<-c(weight_T,list(weight_n[sm_state_num]/sum(weight_n[sm_state_num])))
}
stopCluster(cl)
Sys.time()-start_time
```

## 平滑化結果の図
コアの準備をして、プロット
```{r,eval=FALSE}
cl <- makeCluster(rep('localhost', 7))
clusterExport(cl, c("dmvnorm","g_DR.fn","theta_tau","theta_mu",
                    "sm_state","theta_sigma","proposal_theta_v"))
sm_parameter <- parApply(cl,data.frame(i = length(data_for_Kalman[,1]):1),
                         1,function(i) colSums(sm_state[[i]][,c(1,2)]*
                                     sm_state[[i]][,3]))
stopCluster(cl)

qu<-data.frame(t(sapply(sm_state,function(x) representative_value.fn(x))))
qu <- qu[c(N:1),]
plot_d<-data.frame(dt=c(1:length(data_for_Kalman[,1])),
                   answer=answer$rho,estimate_rho=re_rho,
                   two_fif_rho=qu$two_fif_rho,
                   sm_rho=sm_parameter[1,],
                   twenty_fif_rho=qu$twenty_fif_rho,
                   seventy_fif_rho=qu$seventy_fif_rho,
                   nine_fif=qu$nine_fif_rho)

print(ggplot(plot_d,aes(x=dt))+geom_line(aes(y=answer,colour="answer"))+
        geom_line(aes(y=estimate_rho,colour="filter"),linetype="dashed")+
        geom_line(aes(y=sm_rho,colour="sm"))+
        geom_ribbon(aes(ymin=twenty_fif_rho, ymax=seventy_fif_rho,fill="50%"),alpha = 0.3)+
        geom_ribbon(aes(ymin=two_fif_rho, ymax=nine_fif,fill="90%"),alpha = 0.3)+
        theme_bw(15)+
        theme(legend.position=c(.85,.75),legend.background=element_blank())+
        ylab(expression(rho))+
        scale_color_manual(name='', values=c("answer" = "red", "filter" = "blue","sm"="green"))+
        scale_fill_manual(name='', values=c("50%" = "green", "90%" = "gray")))
  
  
plot_d<-data.frame(dt=c(1:length(data_for_Kalman[,1])),
                   answer=answer$PD,estimate_PD=re_PD,
                   two_fif_pd=qu$two_fif_pd,
                   sm_pd=sm_parameter[2,],
                   twenty_fif_pd=qu$twenty_fif_pd,
                   seventy_fif_pd=qu$seventy_fif_pd,
                   nine_fif=qu$nine_fif_pd)
  
print(ggplot(plot_d,aes(x=dt))+geom_line(aes(y=answer,colour="answer"))+
        geom_line(aes(y=estimate_PD,colour="filter"),linetype="dashed")+
        geom_line(aes(y=sm_pd,colour="sm"))+
        geom_ribbon(aes(ymin=twenty_fif_pd, ymax=seventy_fif_pd,fill="50%"),alpha = 0.3)+
        geom_ribbon(aes(ymin=two_fif_pd, ymax=nine_fif,fill="90%"),alpha = 0.3)+
        theme_bw(15)+
        theme(legend.position=c(.85,.75),legend.background=element_blank())+
        ylab(expression(PD))+
        scale_color_manual(name='', values=c("answer" = "red", "filter" = "blue","sm"="green"))+
        scale_fill_manual(name='', values=c("50%" = "green", "90%" = "gray")))
Sys.time()-start_time
```


